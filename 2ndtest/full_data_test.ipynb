{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data.dataset import random_split\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# Helper Clases / Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAccuracy(model, dataloader):\n",
    "    y_pred_tot = []\n",
    "    y_sample_tot = []\n",
    "    for i_batch, sample_batched in enumerate(dataloader):\n",
    "        X_sample, y_sample = sample_batched\n",
    "        # Flip axis first\n",
    "        X_sample = torch.Tensor(np.moveaxis(X_sample.numpy(), -1, 0))\n",
    "        X_sample, y_sample = Variable(X_sample), Variable(y_sample)\n",
    "        scores = model(X_sample)\n",
    "        #loss = loss_fn(scores, y_sample.long())\n",
    "        #print('val loss: %f' % loss)\n",
    "        _, y_pred = torch.max(scores, 1)\n",
    "        y_pred_tot.append(y_pred.data.numpy())\n",
    "        y_sample_tot.append(y_sample.data.numpy())\n",
    "    acc = np.mean(np.concatenate(y_pred_tot) == np.concatenate(y_sample_tot))\n",
    "    return acc\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out, _ = x\n",
    "        T, N, H = out.size() \n",
    "        return out.view(H, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2280, 23, 1000)\n",
      "(2280,)\n"
     ]
    }
   ],
   "source": [
    "X_all = []\n",
    "y_all = []\n",
    "for i in range(8):\n",
    "    file_path = './../project_datasets/A0' + str(i+1) + 'T_slice.mat'\n",
    "    data = h5py.File(file_path, 'r')\n",
    "    X = np.copy(data['image'])\n",
    "    y = np.copy(data['type'])\n",
    "    X = X[:, 0:23, :]\n",
    "    X_all.append(X)\n",
    "    y = y[0,0:X.shape[0]:1]\n",
    "    y_all.append(y)\n",
    "A, N, E, T = np.shape(X_all)\n",
    "X_all = np.reshape(X_all, (A*N, E, T))\n",
    "y_all = np.reshape(y_all, (-1))\n",
    "y_all = y_all - 769\n",
    "## Remove NAN\n",
    "index_Nan = []\n",
    "for i in range(A*N):\n",
    "    for j in range(E):\n",
    "        if (any(np.isnan(X_all[i,j])) == True):\n",
    "            index_Nan.append(i)\n",
    "X_all = np.delete(X_all, index_Nan, axis=0)\n",
    "y_all = np.delete(y_all, index_Nan)\n",
    "print (np.shape(X_all))\n",
    "print (np.shape(y_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50\n",
    "data = data_utils.TensorDataset(torch.Tensor(X_all), torch.Tensor(y_all))\n",
    "dset = {}\n",
    "dset['train'], dset['val'], dset['test'] = random_split(data, [A*N-100-24, 50, 50])\n",
    "dataloaders = {x: data_utils.DataLoader(dset[x], batch_size=bs, shuffle=True, num_workers=1) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layer, num_class):\n",
    "        super(myLSTM, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layer)\n",
    "                            # batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_class)\n",
    "    def forward(self, x):\n",
    "        # h0 = Variable(torch.zeros(self.n_layer, x.size(1),\n",
    "                                #   self.hidden_dim)).cuda()\n",
    "        # c0 = Variable(torch.zeros(self.n_layer, x.size(1),\n",
    "                                #   self.hidden_dim)).cuda()\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[-1, :, :]\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    def check_accuracy(self, dataloader):\n",
    "        total_correct = 0\n",
    "        total_label = 0\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            X_sample, y_sample = sample_batched\n",
    "            # Flip axis first\n",
    "            X_sample = torch.Tensor(np.moveaxis(X_sample.numpy(), -1, 0))\n",
    "            X_sample, y_sample = Variable(X_sample), Variable(y_sample)\n",
    "            out = self.forward(X_sample)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            num_correct = np.sum(pred.data.numpy() == y_sample.data.numpy())\n",
    "            total_correct += num_correct\n",
    "            total_label += len(pred)\n",
    "        return  total_correct / total_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2203 -0.2453 -0.3081  0.0172\n",
      " 0.1495 -0.1227 -0.1738 -0.0453\n",
      "-0.2960 -0.0887 -0.3827 -0.1091\n",
      " 0.5739 -0.2150 -0.1779  0.0570\n",
      "-0.1596  0.3117 -0.1160  0.4199\n",
      "-0.4519  0.3600 -0.2664  0.2657\n",
      " 0.0435 -0.0735 -0.2059  0.0751\n",
      "-0.0412  0.5323 -0.2088  0.0293\n",
      " 0.2927  0.0531 -0.1833 -0.1989\n",
      " 0.0477  0.0072 -0.0519 -0.1737\n",
      "-0.3693 -0.0575  0.0854  0.3287\n",
      " 0.1823 -0.2499 -0.1397  0.0258\n",
      "-0.0026 -0.0261 -0.1165 -0.1375\n",
      " 0.2373  0.0343 -0.0890  0.1260\n",
      " 0.3349 -0.1221 -0.2317 -0.1338\n",
      "-0.1510 -0.1396 -0.1578 -0.0455\n",
      "-0.1560  0.4234 -0.1441  0.3211\n",
      "-0.4211  0.2914 -0.2639  0.2054\n",
      " 0.0987  0.1358 -0.1212 -0.2163\n",
      " 0.0966 -0.1600 -0.2815  0.0377\n",
      "-0.4738 -0.0890 -0.2148  0.0639\n",
      " 0.1110 -0.0973 -0.3313 -0.1048\n",
      "-0.0772 -0.2529  0.0031 -0.2731\n",
      "-0.2825  0.5513 -0.2748  0.0987\n",
      "-0.1194 -0.1219  0.0548 -0.0664\n",
      "-0.1647  0.6295  0.0629  0.0914\n",
      " 0.2961 -0.1342 -0.1816  0.0351\n",
      "-0.2227 -0.1998  0.0643 -0.1476\n",
      "-0.0561  0.2201  0.0839  0.2283\n",
      "-0.2433  0.4491 -0.2152  0.3947\n",
      "-0.3552  0.1097 -0.1934  0.4188\n",
      " 0.0103 -0.0721 -0.1318 -0.2528\n",
      "-0.0077 -0.2357 -0.1968  0.1103\n",
      " 0.0067  0.0775 -0.1113 -0.1173\n",
      " 0.4481 -0.3574 -0.2816 -0.1761\n",
      "-0.0950 -0.0733 -0.2191  0.0816\n",
      " 0.3020 -0.1550 -0.3427 -0.0571\n",
      " 0.3757 -0.3818  0.0289  0.0284\n",
      " 0.1593  0.0014 -0.1605  0.1008\n",
      "-0.1313  0.1626 -0.0904  0.2752\n",
      "-0.0514 -0.1190 -0.2316  0.0945\n",
      " 0.3360 -0.1629 -0.2256 -0.0448\n",
      "-0.0226 -0.0782 -0.0192 -0.1372\n",
      " 0.2030 -0.1715 -0.1184 -0.0514\n",
      "-0.0028 -0.2939 -0.2299  0.1652\n",
      "-0.3201  0.5567 -0.1460  0.2237\n",
      "-0.1148  0.3745 -0.0184  0.0751\n",
      "-0.3287 -0.2348 -0.2599  0.1003\n",
      "-0.0019  0.0794 -0.1771  0.4956\n",
      " 0.0733  0.1093 -0.2516  0.0418\n",
      "[torch.FloatTensor of size 50x4]\n",
      "\n",
      "torch.Size([50, 4])\n",
      "torch.Size([50])\n",
      "(0 batch) loss: 1.422521\n",
      "Variable containing:\n",
      "-0.3315  0.1193 -0.2118  0.1385\n",
      " 0.0270 -0.1516 -0.2033  0.0762\n",
      "-0.1074  0.2177 -0.1385  0.1988\n",
      " 0.2402  0.0562 -0.1375  0.2853\n",
      "-0.2964 -0.1594 -0.1849  0.0460\n",
      " 0.3029 -0.2051 -0.3842  0.0670\n",
      "-0.0972 -0.1435 -0.2395  0.0786\n",
      " 0.1258  0.1392 -0.1574  0.2580\n",
      " 0.1416  0.0522  0.0315  0.1771\n",
      " 0.2134 -0.0814 -0.1741 -0.0130\n",
      "-0.0084 -0.0516  0.0801 -0.0703\n",
      "-0.2943 -0.0580  0.1141  0.2771\n",
      " 0.0357 -0.1250 -0.1785  0.0210\n",
      " 0.0711 -0.0634 -0.0634  0.1899\n",
      " 0.0082  0.0880  0.0329  0.1660\n",
      " 0.0562  0.0319 -0.0504  0.3194\n",
      " 0.1942 -0.1605 -0.0854  0.1998\n",
      "-0.0277 -0.0357  0.1821  0.0792\n",
      "-0.0104  0.0701 -0.3380 -0.0422\n",
      "-0.2641 -0.1534 -0.0703  0.1317\n",
      " 0.0674 -0.1727 -0.1119  0.1473\n",
      "-0.3059 -0.0274 -0.1087  0.2758\n",
      "-0.0424 -0.0707 -0.1215 -0.1995\n",
      " 0.2302 -0.2852 -0.0305 -0.1105\n",
      "-0.3592 -0.1257 -0.0814  0.0997\n",
      "-0.2283  0.0162 -0.1477  0.4416\n",
      "-0.0809 -0.0925  0.1058  0.1403\n",
      " 0.1807 -0.1907 -0.0589  0.1136\n",
      "-0.2406  0.1444 -0.0445  0.3495\n",
      "-0.2448 -0.0464 -0.2284  0.1788\n",
      "-0.4422 -0.0064 -0.1413  0.2267\n",
      "-0.1494  0.3646 -0.2754  0.4170\n",
      " 0.1146 -0.2251 -0.4025  0.0228\n",
      "-0.3256 -0.1922 -0.2730  0.4050\n",
      " 0.1334 -0.0701 -0.4017 -0.0348\n",
      " 0.0034 -0.0166 -0.6658 -0.1084\n",
      " 0.1186 -0.0978 -0.3136 -0.0170\n",
      " 0.1715 -0.2548 -0.1075  0.4433\n",
      "-0.4606  0.3107 -0.2536  0.2759\n",
      " 0.4147 -0.1095 -0.1733 -0.1196\n",
      " 0.2365 -0.0968 -0.2057  0.0419\n",
      "-0.0028 -0.0613 -0.1316  0.4395\n",
      "-0.1020 -0.0972 -0.2319  0.0889\n",
      " 0.4370  0.1001 -0.0655  0.2002\n",
      " 0.0856  0.0523 -0.2331 -0.1153\n",
      "-0.2759 -0.2505 -0.0913  0.1737\n",
      " 0.0757  0.2305  0.2460  0.3544\n",
      " 0.0641 -0.2190 -0.0239 -0.1153\n",
      " 0.0991 -0.0110 -0.0592  0.0179\n",
      "-0.3883 -0.3134 -0.1428  0.1954\n",
      "[torch.FloatTensor of size 50x4]\n",
      "\n",
      "torch.Size([50, 4])\n",
      "torch.Size([50])\n",
      "(1 batch) loss: 1.415025\n",
      "Variable containing:\n",
      " 0.3024  0.1598  0.1895  0.2557\n",
      "-0.0102 -0.2543  0.0198  0.0524\n",
      "-0.1739  0.1618  0.0185  0.0145\n",
      " 0.0772 -0.0942 -0.0727 -0.0183\n",
      " 0.1282 -0.1930 -0.5461  0.1194\n",
      "-0.0114  0.4010 -0.1485  0.2416\n",
      "-0.1540 -0.0613 -0.2895  0.0649\n",
      "-0.0558 -0.2020 -0.0605  0.1057\n",
      " 0.1642 -0.3810 -0.2347  0.0145\n",
      "-0.0233 -0.0122 -0.2182  0.0440\n",
      "-0.1441  0.0094 -0.1192  0.1069\n",
      " 0.1670 -0.1687 -0.3895  0.1039\n",
      " 0.1122  0.1740 -0.2585  0.0287\n",
      "-0.5816  0.0119 -0.4459 -0.0669\n",
      "-0.2681  0.4278 -0.1923  0.2504\n",
      " 0.0300 -0.1834 -0.6300  0.0910\n",
      "-0.1045 -0.0593 -0.1590  0.1376\n",
      " 0.0256 -0.2742 -0.0483  0.0098\n",
      " 0.0347  0.1213  0.0508  0.1724\n",
      " 0.0168  0.1988  0.1119  0.0905\n",
      "-0.2263 -0.1249  0.0205  0.3639\n",
      "-0.0036 -0.0873 -0.1259  0.1031\n",
      " 0.0157 -0.0582 -0.1052  0.1906\n",
      " 0.1278 -0.3125 -0.3527 -0.0383\n",
      "-0.0992 -0.1831 -0.0965 -0.0777\n",
      " 0.0825  0.0234  0.1459  0.2518\n",
      " 0.3290 -0.2165 -0.5360  0.0850\n",
      "-0.0851 -0.2597 -0.4293  0.0264\n",
      "-0.3572 -0.1327 -0.0685 -0.0637\n",
      " 0.3500 -0.2825 -0.1779 -0.0585\n",
      " 0.2077  0.1299 -0.1057  0.1962\n",
      " 0.0081  0.1204  0.0539  0.1687\n",
      " 0.0712  0.1267 -0.1749  0.2697\n",
      " 0.1176 -0.2367 -0.4415  0.2706\n",
      "-0.1940 -0.1349  0.1597  0.2637\n",
      "-0.0733 -0.0491 -0.0429  0.2782\n",
      " 0.2059 -0.4386 -0.4202  0.1061\n",
      " 0.5566 -0.3194 -0.3505  0.0229\n",
      "-0.1082  0.0954  0.0408  0.4119\n",
      "-0.2754 -0.0588 -0.2587  0.3029\n",
      " 0.2587 -0.2329 -0.6165 -0.1800\n",
      " 0.1340 -0.1781 -0.1813  0.0920\n",
      " 0.1920 -0.0652 -0.4207  0.0799\n",
      " 0.0223 -0.2011 -0.5538 -0.0562\n",
      "-0.0490 -0.0386 -0.3290  0.1730\n",
      " 0.3937 -0.3135 -0.3425 -0.0368\n",
      "-0.0357  0.0229 -0.2104  0.1513\n",
      "-0.3904 -0.1594 -0.0334  0.0830\n",
      "-0.2387  0.3557 -0.2017  0.2138\n",
      "-0.1673  0.2196 -0.0588  0.2373\n",
      "[torch.FloatTensor of size 50x4]\n",
      "\n",
      "torch.Size([50, 4])\n",
      "torch.Size([50])\n",
      "(2 batch) loss: 1.381115\n",
      "Variable containing:\n",
      "-0.1789 -0.0945 -0.0490  0.3206\n",
      "-0.1025 -0.1438 -0.1393  0.0613\n",
      "-0.0476 -0.1513 -0.1158  0.0819\n",
      " 0.1183 -0.1458 -0.5125 -0.1203\n",
      "-0.1653 -0.1403  0.1445  0.1917\n",
      " 0.1413 -0.0880 -0.0353 -0.0007\n",
      " 0.1361 -0.0265 -0.1641  0.1417\n",
      "-0.2937 -0.1582 -0.0623 -0.0007\n",
      " 0.0515  0.0505  0.0317  0.4059\n",
      "-0.1912 -0.0034  0.0132  0.2729\n",
      "-0.0536 -0.0722 -0.1887  0.2316\n",
      " 0.0326 -0.2216 -0.0693  0.0826\n",
      " 0.2476 -0.1752 -0.2941  0.0595\n",
      "-0.7378 -0.0496 -0.3369  0.0846\n",
      " 0.2006 -0.4014 -0.4981  0.1415\n",
      "-0.4460 -0.2953  0.0817  0.1178\n",
      "-0.0204 -0.0200 -0.2314  0.0638\n",
      "-0.1508  0.0398 -0.2265  0.3271\n",
      " 0.2364 -0.3549 -0.1511  0.2061\n",
      " 0.1592  0.0057 -0.0225  0.1616\n",
      "-0.0367 -0.1023 -0.0940  0.1231\n",
      " 0.0636 -0.2179 -0.3964  0.1237\n",
      "-0.2765 -0.0172  0.0325  0.1640\n",
      "-0.2870  0.0476 -0.0144  0.1608\n",
      "-0.0863 -0.0375  0.1148  0.0209\n",
      " 0.1394 -0.1172  0.1133 -0.0751\n",
      "-0.1778  0.1293  0.0493  0.0571\n",
      "-0.0783 -0.0393 -0.1604 -0.0793\n",
      " 0.0744 -0.0985 -0.1368  0.0253\n",
      " 0.1419 -0.1691 -0.4478 -0.0821\n",
      "-0.0657  0.0682 -0.0829  0.0798\n",
      " 0.0390 -0.1410 -0.4403  0.0835\n",
      " 0.1011  0.2772  0.0368  0.0294\n",
      " 0.2295 -0.3616 -0.3935  0.1640\n",
      " 0.0769 -0.1746 -0.5316 -0.1921\n",
      "-0.0189 -0.2089  0.0241  0.0249\n",
      "-0.3296  0.3080 -0.1890  0.1904\n",
      "-0.0484 -0.0732 -0.0138  0.0198\n",
      " 0.1563 -0.1156 -0.1330 -0.0825\n",
      "-0.0464 -0.2276 -0.3936 -0.0725\n",
      "-0.0881  0.0693  0.0324  0.0079\n",
      "-0.1410 -0.0714  0.0362  0.2907\n",
      "-0.4049  0.0674 -0.3554 -0.0997\n",
      " 0.1523 -0.3563  0.0381 -0.1002\n",
      " 0.2677 -0.0089 -0.1329  0.0340\n",
      " 0.3024 -0.2658 -0.2327  0.0231\n",
      "-0.1393  0.1088 -0.1139 -0.1743\n",
      "-0.2383 -0.0681  0.0651  0.0235\n",
      "-0.0107 -0.3740 -0.1952  0.2578\n",
      "-0.2897 -0.1268  0.1086 -0.1427\n",
      "[torch.FloatTensor of size 50x4]\n",
      "\n",
      "torch.Size([50, 4])\n",
      "torch.Size([50])\n",
      "(3 batch) loss: 1.395073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/andrew/Desktop/Project/2ndtest/.env/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7fedeed727b8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/andrew/Desktop/Project/2ndtest/.env/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/andrew/Desktop/Project/2ndtest/.env/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 345, in get\n",
      "    return ForkingPickler.loads(res)\n",
      "  File \"/home/andrew/Desktop/Project/2ndtest/.env/lib/python3.5/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7691f5912405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# zero the parameter gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Project/2ndtest/.env/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Project/2ndtest/.env/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "hidden_dim = 100\n",
    "num_classes = 4\n",
    "num_epoches = 10\n",
    "model = myLSTM(E, hidden_dim, 1, num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(num_epoches):\n",
    "    for i, data in enumerate(dataloaders['train'], 0):\n",
    "        X_train, y_train = data\n",
    "        # Wrap them in Variable\n",
    "        # Flip axis first\n",
    "        X_train = torch.Tensor(np.moveaxis(X_train.numpy(), -1, 0))\n",
    "        X_train, y_train = Variable(X_train), Variable(y_train)\n",
    "        # forward + backward + optimize\n",
    "        out = model(X_train)\n",
    "        print (out)\n",
    "        print (out.size())\n",
    "        print (y_train.size())\n",
    "        loss = loss_fn(out, y_train.long())\n",
    "        print('(%d batch) loss: %f' % (i, loss))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_acc = model.check_accuracy(dataloaders['train'])\n",
    "    val_acc = model.check_accuracy(dataloaders['val'])\n",
    "    print('(Epoch %d / %d) train_acc: %f; val_acc: %f' % (epoch+1, num_epoches, train_acc, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
